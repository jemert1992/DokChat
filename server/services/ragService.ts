import { storage } from "../storage";
import { OpenAIService } from "./openaiService";
import { MultiAIService } from "./multiAIService";
import type { Document, DocumentAnalysis, InsertDocumentAnalysis } from "../../shared/schema";

interface DocumentEmbedding {
  documentId: number;
  chunkId: string;
  text: string;
  embedding: number[];
  metadata: {
    industry: string;
    documentType: string;
    entityTypes: string[];
    confidence: number;
    createdAt: string;
  };
}

interface RetrievedDocument {
  document: Document;
  similarity: number;
  relevantChunks: {
    text: string;
    similarity: number;
    metadata: any;
  }[];
  reasonForRelevance: string;
}

interface RAGContext {
  query: string;
  retrievedDocuments: RetrievedDocument[];
  totalDocumentsSearched: number;
  averageSimilarity: number;
  contextSummary: string;
  enhancementStrategy: 'terminology_support' | 'pattern_recognition' | 'comparative_analysis' | 'domain_expertise';
}

interface RAGEnhancedAnalysis {
  originalAnalysis: any;
  ragContext: RAGContext;
  enhancedInsights: string[];
  contextualRecommendations: string[];
  confidenceBoost: number;
  historicalComparisons: string[];
  industryBenchmarks: {
    averageConfidence: number;
    commonPatterns: string[];
    typicalProcessingTime: number;
    qualityIndicators: string[];
  };
}

/**
 * Advanced RAG (Retrieval Augmented Generation) Service for DOKTECH 3.0
 * 
 * Enhances document processing accuracy by retrieving relevant context from 
 * historical documents and domain knowledge to improve AI analysis quality.
 * 
 * Key Capabilities:
 * - Document corpus indexing with vector embeddings
 * - Semantic similarity search for context retrieval  
 * - Multi-dimensional relevance scoring
 * - Context-aware analysis enhancement
 * - Industry-specific knowledge augmentation
 * - Historical pattern recognition and benchmarking
 */
export class RAGService {
  private openaiService: OpenAIService;
  private multiAIService: MultiAIService;
  private documentEmbeddings: Map<number, DocumentEmbedding[]> = new Map();
  private isIndexed: boolean = false;

  constructor() {
    this.openaiService = new OpenAIService();
    this.multiAIService = new MultiAIService();
    this.initializeDocumentIndex();
  }

  /**
   * Initialize document corpus with vector embeddings for efficient retrieval
   */
  private async initializeDocumentIndex(): Promise<void> {
    console.log('üîÑ Initializing RAG document corpus...');
    
    try {
      // Check if we already have embeddings stored
      // Get recent documents to check for existing embeddings
      const documents = await storage.getDocuments();
      const analysisPromises = documents.slice(0, 10).map(doc => storage.getDocumentAnalyses(doc.id));
      const allAnalyses = await Promise.all(analysisPromises);
      const existingEmbeddings = allAnalyses.flat();
      const embeddingAnalyses = existingEmbeddings.filter(analysis => 
        analysis.analysisType === 'document_embedding'
      );

      if (embeddingAnalyses.length > 0) {
        console.log(`‚úÖ Loading ${embeddingAnalyses.length} existing document embeddings`);
        await this.loadExistingEmbeddings(embeddingAnalyses);
      } else {
        console.log('üîÑ No existing embeddings found, generating fresh index...');
        await this.generateDocumentEmbeddings();
      }

      this.isIndexed = true;
      console.log(`‚úÖ RAG document corpus indexed with ${this.documentEmbeddings.size} documents`);
      
    } catch (error) {
      console.error('‚ùå Failed to initialize document index:', error);
      this.isIndexed = false;
    }
  }

  /**
   * Generate embeddings for all documents in the corpus
   */
  private async generateDocumentEmbeddings(): Promise<void> {
    const documents = await storage.getDocuments();
    console.log(`üîÑ Generating embeddings for ${documents.length} documents...`);

    for (const document of documents) {
      if (document.extractedText && document.extractedText.length > 50) {
        try {
          await this.createDocumentEmbedding(document);
        } catch (error) {
          console.warn(`‚ö†Ô∏è Failed to create embedding for document ${document.id}:`, error);
        }
      }
    }
  }

  /**
   * Create vector embedding for a single document
   */
  private async createDocumentEmbedding(document: Document): Promise<void> {
    if (!document.extractedText) return;

    try {
      // Split document into chunks for better retrieval granularity
      const chunks = this.splitTextIntoChunks(document.extractedText, 1000, 200);
      const documentEmbeddings: DocumentEmbedding[] = [];

      for (let i = 0; i < chunks.length; i++) {
        const chunk = chunks[i];
        
        // Generate embedding using OpenAI
        const embedding = await this.generateTextEmbedding(chunk);
        
        // Extract entity types from existing document data
        const entityTypes = this.extractEntityTypesFromDocument(document);
        
        const documentEmbedding: DocumentEmbedding = {
          documentId: document.id,
          chunkId: `${document.id}_chunk_${i}`,
          text: chunk,
          embedding,
          metadata: {
            industry: document.industry,
            documentType: document.documentType || 'unknown',
            entityTypes,
            confidence: document.aiConfidence || 0.7,
            createdAt: document.createdAt?.toISOString() || new Date().toISOString()
          }
        };

        documentEmbeddings.push(documentEmbedding);
      }

      // Store embeddings in memory cache
      this.documentEmbeddings.set(document.id, documentEmbeddings);

      // Persist embeddings to database for future use
      await storage.createDocumentAnalysis({
        documentId: document.id,
        analysisType: 'document_embedding',
        analysisData: {
          embeddings: documentEmbeddings.map(emb => ({
            chunkId: emb.chunkId,
            text: emb.text.substring(0, 500), // Store first 500 chars for context
            embedding: emb.embedding,
            metadata: emb.metadata
          }))
        },
        confidenceScore: document.aiConfidence || 0.7
      });

      console.log(`‚úÖ Created ${documentEmbeddings.length} embeddings for document ${document.id}`);

    } catch (error) {
      console.error(`‚ùå Failed to create embedding for document ${document.id}:`, error);
      throw error;
    }
  }

  /**
   * Generate text embedding using OpenAI embeddings API
   */
  private async generateTextEmbedding(text: string): Promise<number[]> {
    // For now, we'll simulate embeddings since OpenAI embeddings require specific API setup
    // In production, this would use OpenAI's text-embedding-ada-002 model
    
    // Create a simple hash-based embedding simulation
    const words = text.toLowerCase().split(/\s+/).slice(0, 100); // First 100 words
    const embedding = new Array(1536).fill(0); // OpenAI embedding dimension
    
    // Generate pseudo-embedding based on text characteristics
    for (let i = 0; i < words.length; i++) {
      const word = words[i];
      const hash = this.simpleHash(word);
      const index = Math.abs(hash) % 1536;
      embedding[index] += 1.0 / (i + 1); // Weight by position
    }
    
    // Normalize the embedding vector
    const magnitude = Math.sqrt(embedding.reduce((sum, val) => sum + val * val, 0));
    return embedding.map(val => magnitude > 0 ? val / magnitude : 0);
  }

  /**
   * Simple hash function for pseudo-embedding generation
   */
  private simpleHash(str: string): number {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // Convert to 32-bit integer
    }
    return hash;
  }

  /**
   * Split text into overlapping chunks for better retrieval
   */
  private splitTextIntoChunks(text: string, chunkSize: number, overlap: number): string[] {
    const words = text.split(/\s+/);
    const chunks: string[] = [];
    
    for (let i = 0; i < words.length; i += chunkSize - overlap) {
      const chunk = words.slice(i, i + chunkSize).join(' ');
      if (chunk.trim().length > 50) { // Minimum chunk size
        chunks.push(chunk);
      }
    }
    
    return chunks.length > 0 ? chunks : [text]; // Fallback to full text if no chunks
  }

  /**
   * Extract entity types from document for metadata
   */
  private extractEntityTypesFromDocument(document: Document): string[] {
    const entityTypes: Set<string> = new Set();
    
    // Extract from document type
    if (document.documentType) {
      entityTypes.add(document.documentType);
    }
    
    // Extract from industry
    entityTypes.add(document.industry);
    
    // Extract from extracted data if available
    if (document.extractedData && typeof document.extractedData === 'object') {
      const data = document.extractedData as any;
      if (data.entities) {
        data.entities.forEach((entity: any) => {
          if (entity.type) entityTypes.add(entity.type);
        });
      }
    }
    
    return Array.from(entityTypes);
  }

  /**
   * Load existing embeddings from database into memory
   */
  private async loadExistingEmbeddings(embeddingAnalyses: DocumentAnalysis[]): Promise<void> {
    for (const analysis of embeddingAnalyses) {
      if (analysis.analysisData && typeof analysis.analysisData === 'object') {
        const data = analysis.analysisData as any;
        if (data.embeddings && Array.isArray(data.embeddings)) {
          const documentEmbeddings: DocumentEmbedding[] = data.embeddings.map((emb: any) => ({
            documentId: analysis.documentId,
            chunkId: emb.chunkId,
            text: emb.text,
            embedding: emb.embedding,
            metadata: emb.metadata
          }));
          
          this.documentEmbeddings.set(analysis.documentId, documentEmbeddings);
        }
      }
    }
  }

  /**
   * Retrieve relevant documents using hybrid BM25 + semantic search
   * BEST PRACTICE: Combines keyword matching with semantic understanding
   */
  async retrieveRelevantContext(
    query: string, 
    industry: string, 
    documentType?: string,
    maxResults: number = 5
  ): Promise<RAGContext> {
    if (!this.isIndexed) {
      console.warn('‚ö†Ô∏è Document index not ready, initializing...');
      await this.initializeDocumentIndex();
    }

    console.log(`üîç Hybrid retrieval (BM25 + Semantic) for: "${query.substring(0, 100)}..."`);

    try {
      // STEP 1: BM25 Keyword Search (40% weight) - with fallback handling
      const bm25Results = this.calculateBM25Scores(query, industry, documentType);
      
      // STEP 2: Semantic Search (60% weight)
      const queryEmbedding = await this.generateTextEmbedding(query);
      
      // Calculate semantic similarities with all document chunks
      const semanticResults: Array<{
        documentId: number;
        chunkId: string;
        text: string;
        similarity: number;
        metadata: any;
      }> = [];

      const docIds = Array.from(this.documentEmbeddings.keys());
      for (const docId of docIds) {
        const embeddings = this.documentEmbeddings.get(docId)!;
        for (const embedding of embeddings) {
          // Filter by industry if specified
          if (industry !== 'general' && embedding.metadata.industry !== industry) {
            continue;
          }
          
          // Filter by document type if specified  
          if (documentType && embedding.metadata.documentType !== documentType) {
            continue;
          }

          const similarity = this.calculateCosineSimilarity(queryEmbedding, embedding.embedding);
          
          if (similarity > 0.1) { // Minimum similarity threshold
            semanticResults.push({
              documentId: docId,
              chunkId: embedding.chunkId,
              text: embedding.text,
              similarity,
              metadata: embedding.metadata
            });
          }
        }
      }

      // STEP 3: Hybrid Reranking with fallback handling
      let topSimilarities: Array<{ documentId: number; chunkId: string; text: string; similarity: number; metadata: any }>;
      
      if (bm25Results.length === 0 && semanticResults.length > 0) {
        // Fallback: semantic-only (BM25 corpus empty)
        console.log('‚ö†Ô∏è BM25 returned no results, using semantic-only retrieval');
        topSimilarities = semanticResults
          .sort((a, b) => b.similarity - a.similarity)
          .slice(0, maxResults * 2);
      } else if (semanticResults.length === 0 && bm25Results.length > 0) {
        // Fallback: BM25-only (no semantic matches)
        console.log('‚ö†Ô∏è Semantic search returned no results, using BM25-only retrieval');
        topSimilarities = bm25Results
          .map(r => ({
            documentId: r.documentId,
            chunkId: r.chunkId,
            text: r.text,
            similarity: r.bm25Score / Math.max(...bm25Results.map(b => b.bm25Score), 1),
            metadata: r.metadata
          }))
          .sort((a, b) => b.similarity - a.similarity)
          .slice(0, maxResults * 2);
      } else if (bm25Results.length > 0 && semanticResults.length > 0) {
        // Hybrid: combine both signals
        const hybridScores = this.hybridRerank(bm25Results, semanticResults);
        topSimilarities = hybridScores
          .sort((a, b) => b.hybridScore - a.hybridScore)
          .slice(0, maxResults * 2);
      } else {
        // Empty corpus - return empty results
        topSimilarities = [];
      }

      // Group by document and get full document info
      const documentGroups = new Map<number, typeof topSimilarities>();
      for (const sim of topSimilarities) {
        if (!documentGroups.has(sim.documentId)) {
          documentGroups.set(sim.documentId, []);
        }
        documentGroups.get(sim.documentId)!.push(sim);
      }

      // Build retrieved documents
      const retrievedDocuments: RetrievedDocument[] = [];
      const docEntries = Array.from(documentGroups.entries()).slice(0, maxResults);
      for (const [docId, chunks] of docEntries) {
        const document = await storage.getDocument(docId);
        if (document) {
          const avgSimilarity = chunks.reduce((sum, c) => sum + c.similarity, 0) / chunks.length;
          
          retrievedDocuments.push({
            document,
            similarity: avgSimilarity,
            relevantChunks: chunks.slice(0, 3).map(c => ({ // Top 3 chunks per document
              text: c.text,
              similarity: c.similarity,
              metadata: c.metadata
            })),
            reasonForRelevance: this.generateRelevanceReason(query, chunks[0], document)
          });
        }
      }

      // Calculate context summary
      const contextSummary = await this.generateContextSummary(query, retrievedDocuments);
      
      const ragContext: RAGContext = {
        query,
        retrievedDocuments,
        totalDocumentsSearched: this.documentEmbeddings.size,
        averageSimilarity: retrievedDocuments.length > 0 
          ? retrievedDocuments.reduce((sum, doc) => sum + doc.similarity, 0) / retrievedDocuments.length 
          : 0,
        contextSummary,
        enhancementStrategy: this.determineEnhancementStrategy(retrievedDocuments, industry)
      };

      console.log(`‚úÖ Retrieved ${retrievedDocuments.length} relevant documents with avg similarity ${Math.round(ragContext.averageSimilarity * 100)}%`);
      return ragContext;

    } catch (error) {
      console.error('‚ùå Failed to retrieve relevant context:', error);
      
      // Return empty context on failure
      return {
        query,
        retrievedDocuments: [],
        totalDocumentsSearched: 0,
        averageSimilarity: 0,
        contextSummary: 'No relevant context retrieved due to error',
        enhancementStrategy: 'terminology_support'
      };
    }
  }

  /**
   * BM25 scoring for keyword-based retrieval
   * BEST PRACTICE: Complements semantic search with traditional IR
   */
  private calculateBM25Scores(
    query: string,
    industry: string,
    documentType?: string
  ): Array<{ documentId: number; chunkId: string; text: string; bm25Score: number; metadata: any }> {
    const k1 = 1.5; // Term saturation parameter
    const b = 0.75; // Length normalization parameter
    
    // Tokenize query
    const queryTerms = this.tokenize(query.toLowerCase());
    
    // Collect all documents and calculate avgdl
    const allChunks: Array<{ documentId: number; chunkId: string; text: string; tokens: string[]; metadata: any }> = [];
    let totalLength = 0;
    
    const docIds = Array.from(this.documentEmbeddings.keys());
    for (const docId of docIds) {
      const embeddings = this.documentEmbeddings.get(docId)!;
      for (const embedding of embeddings) {
        // Filter by industry/type
        if (industry !== 'general' && embedding.metadata.industry !== industry) continue;
        if (documentType && embedding.metadata.documentType !== documentType) continue;
        
        const tokens = this.tokenize(embedding.text.toLowerCase());
        allChunks.push({
          documentId: docId,
          chunkId: embedding.chunkId,
          text: embedding.text,
          tokens,
          metadata: embedding.metadata
        });
        totalLength += tokens.length;
      }
    }
    
    const avgdl = allChunks.length > 0 ? totalLength / allChunks.length : 0;
    
    // Calculate document frequency (DF) for each query term
    const df = new Map<string, number>();
    for (const term of queryTerms) {
      df.set(term, 0);
    }
    
    for (const chunk of allChunks) {
      const uniqueTerms = new Set(chunk.tokens);
      for (const term of queryTerms) {
        if (uniqueTerms.has(term)) {
          df.set(term, (df.get(term) || 0) + 1);
        }
      }
    }
    
    // Calculate BM25 score for each chunk
    const results = [];
    for (const chunk of allChunks) {
      let score = 0;
      const docLength = chunk.tokens.length;
      
      for (const term of queryTerms) {
        // Term frequency in this document
        const tf = chunk.tokens.filter(t => t === term).length;
        
        // IDF: log((N - df + 0.5) / (df + 0.5))
        const idf = Math.log((allChunks.length - (df.get(term) || 0) + 0.5) / ((df.get(term) || 0) + 0.5));
        
        // BM25 formula
        score += idf * ((tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (docLength / avgdl))));
      }
      
      if (score > 0) {
        results.push({
          documentId: chunk.documentId,
          chunkId: chunk.chunkId,
          text: chunk.text,
          bm25Score: score,
          metadata: chunk.metadata
        });
      }
    }
    
    return results;
  }
  
  /**
   * Tokenize text into terms for BM25
   */
  private tokenize(text: string): string[] {
    // Simple tokenization: lowercase, remove punctuation, split on whitespace
    return text
      .replace(/[^\w\s]/g, ' ')
      .split(/\s+/)
      .filter(t => t.length > 2); // Remove very short tokens
  }
  
  /**
   * Hybrid reranking: combines BM25 (40%) and semantic (60%) scores
   * BEST PRACTICE: Balances keyword matching with semantic understanding
   * ROBUST: Handles partial overlaps and missing signals gracefully
   */
  private hybridRerank(
    bm25Results: Array<{ documentId: number; chunkId: string; text: string; bm25Score: number; metadata: any }>,
    semanticResults: Array<{ documentId: number; chunkId: string; text: string; similarity: number; metadata: any }>
  ): Array<{ documentId: number; chunkId: string; text: string; similarity: number; hybridScore: number; metadata: any }> {
    // Handle edge cases
    if (bm25Results.length === 0) {
      // Semantic-only: use full weight for semantic
      return semanticResults.map(s => ({
        ...s,
        hybridScore: s.similarity
      }));
    }
    
    if (semanticResults.length === 0) {
      // BM25-only: normalize and use full weight
      const maxBM25 = Math.max(...bm25Results.map(r => r.bm25Score), 1);
      return bm25Results.map(b => ({
        documentId: b.documentId,
        chunkId: b.chunkId,
        text: b.text,
        similarity: 0,
        hybridScore: b.bm25Score / maxBM25,
        metadata: b.metadata
      }));
    }
    
    // Normalize BM25 scores to 0-1 range
    const maxBM25 = Math.max(...bm25Results.map(r => r.bm25Score), 1);
    const normalizedBM25 = new Map<string, number>();
    for (const result of bm25Results) {
      normalizedBM25.set(result.chunkId, result.bm25Score / maxBM25);
    }
    
    // Create semantic lookup for efficiency
    const semanticMap = new Map(semanticResults.map(s => [s.chunkId, s]));
    
    // Combine scores: 40% BM25 + 60% semantic (when both present)
    const BM25_WEIGHT = 0.4;
    const SEMANTIC_WEIGHT = 0.6;
    
    const hybridResults: Array<{ documentId: number; chunkId: string; text: string; similarity: number; hybridScore: number; metadata: any }> = [];
    const processedChunks = new Set<string>();
    
    // Process all semantic results
    for (const semantic of semanticResults) {
      const bm25Score = normalizedBM25.get(semantic.chunkId);
      const hybridScore = bm25Score !== undefined
        ? (bm25Score * BM25_WEIGHT) + (semantic.similarity * SEMANTIC_WEIGHT)
        : semantic.similarity * SEMANTIC_WEIGHT; // Semantic-only for this chunk
      
      hybridResults.push({
        documentId: semantic.documentId,
        chunkId: semantic.chunkId,
        text: semantic.text,
        similarity: semantic.similarity,
        hybridScore,
        metadata: semantic.metadata
      });
      processedChunks.add(semantic.chunkId);
    }
    
    // Add BM25-only results that didn't have semantic matches
    for (const bm25 of bm25Results) {
      if (!processedChunks.has(bm25.chunkId)) {
        const bm25Score = normalizedBM25.get(bm25.chunkId) || 0;
        hybridResults.push({
          documentId: bm25.documentId,
          chunkId: bm25.chunkId,
          text: bm25.text,
          similarity: 0, // No semantic match
          hybridScore: bm25Score * BM25_WEIGHT, // BM25-only for this chunk
          metadata: bm25.metadata
        });
      }
    }
    
    return hybridResults;
  }

  /**
   * Calculate cosine similarity between two vectors
   */
  private calculateCosineSimilarity(vec1: number[], vec2: number[]): number {
    if (vec1.length !== vec2.length) return 0;
    
    let dotProduct = 0;
    let magnitude1 = 0;
    let magnitude2 = 0;
    
    for (let i = 0; i < vec1.length; i++) {
      dotProduct += vec1[i] * vec2[i];
      magnitude1 += vec1[i] * vec1[i];
      magnitude2 += vec2[i] * vec2[i];
    }
    
    const magnitude = Math.sqrt(magnitude1) * Math.sqrt(magnitude2);
    return magnitude > 0 ? dotProduct / magnitude : 0;
  }

  /**
   * Generate reason for why a document is relevant
   */
  private generateRelevanceReason(query: string, similarChunk: any, document: Document): string {
    const reasons = [];
    
    if (similarChunk.similarity > 0.8) {
      reasons.push('high semantic similarity');
    }
    
    if (document.industry !== 'general') {
      reasons.push(`${document.industry} industry match`);
    }
    
    if (document.documentType) {
      reasons.push(`${document.documentType} document type`);
    }
    
    return reasons.length > 0 ? reasons.join(', ') : 'contextual relevance';
  }

  /**
   * Generate context summary from retrieved documents
   */
  private async generateContextSummary(query: string, retrievedDocs: RetrievedDocument[]): Promise<string> {
    if (retrievedDocs.length === 0) {
      return 'No relevant historical context found';
    }

    const contextTexts = retrievedDocs
      .map(doc => doc.relevantChunks[0]?.text.substring(0, 200))
      .filter(Boolean)
      .slice(0, 3);

    const summaryPrompt = `
    Based on these relevant document excerpts for the query "${query}":
    
    ${contextTexts.map((text, i) => `${i + 1}. ${text}...`).join('\n')}
    
    Provide a brief 2-3 sentence summary of the relevant historical context that could help improve document analysis accuracy.
    `;

    try {
      const result = await this.openaiService.analyzeDocument(summaryPrompt, 'general');
      return result.summary || 'Historical documents provide relevant context for improved analysis';
    } catch (error) {
      console.error('Failed to generate context summary:', error);
      return `Found ${retrievedDocs.length} relevant historical documents for enhanced analysis`;
    }
  }

  /**
   * Determine the best enhancement strategy based on retrieved context
   */
  private determineEnhancementStrategy(
    retrievedDocs: RetrievedDocument[], 
    industry: string
  ): RAGContext['enhancementStrategy'] {
    if (retrievedDocs.length === 0) return 'terminology_support';
    
    const avgSimilarity = retrievedDocs.reduce((sum, doc) => sum + doc.similarity, 0) / retrievedDocs.length;
    
    if (avgSimilarity > 0.8) return 'comparative_analysis';
    if (industry !== 'general') return 'domain_expertise';
    if (retrievedDocs.length > 3) return 'pattern_recognition';
    
    return 'terminology_support';
  }

  /**
   * Enhance document analysis using RAG context
   */
  async enhanceAnalysisWithRAG(
    originalAnalysis: any,
    query: string,
    industry: string,
    documentType?: string
  ): Promise<RAGEnhancedAnalysis> {
    console.log('üîÑ Enhancing analysis with RAG context...');

    try {
      // Retrieve relevant context
      const ragContext = await this.retrieveRelevantContext(query, industry, documentType);
      
      // Generate enhanced insights based on context
      const enhancedInsights = await this.generateEnhancedInsights(originalAnalysis, ragContext);
      
      // Generate contextual recommendations
      const contextualRecommendations = await this.generateContextualRecommendations(originalAnalysis, ragContext);
      
      // Calculate confidence boost from context
      const confidenceBoost = this.calculateConfidenceBoost(ragContext);
      
      // Generate historical comparisons
      const historicalComparisons = this.generateHistoricalComparisons(originalAnalysis, ragContext);
      
      // Generate industry benchmarks
      const industryBenchmarks = await this.generateIndustryBenchmarks(industry, ragContext);

      const ragEnhancedAnalysis: RAGEnhancedAnalysis = {
        originalAnalysis,
        ragContext,
        enhancedInsights,
        contextualRecommendations,
        confidenceBoost,
        historicalComparisons,
        industryBenchmarks
      };

      console.log(`‚úÖ RAG enhancement completed with ${enhancedInsights.length} insights and ${confidenceBoost}% confidence boost`);
      return ragEnhancedAnalysis;

    } catch (error) {
      console.error('‚ùå RAG enhancement failed:', error);
      
      // Return minimal enhancement on failure
      return {
        originalAnalysis,
        ragContext: {
          query,
          retrievedDocuments: [],
          totalDocumentsSearched: 0,
          averageSimilarity: 0,
          contextSummary: 'RAG enhancement unavailable',
          enhancementStrategy: 'terminology_support'
        },
        enhancedInsights: [],
        contextualRecommendations: [],
        confidenceBoost: 0,
        historicalComparisons: [],
        industryBenchmarks: {
          averageConfidence: 0.7,
          commonPatterns: [],
          typicalProcessingTime: 5000,
          qualityIndicators: []
        }
      };
    }
  }

  /**
   * Generate enhanced insights using RAG context
   */
  private async generateEnhancedInsights(
    originalAnalysis: any,
    ragContext: RAGContext
  ): Promise<string[]> {
    const insights: string[] = [];
    
    if (ragContext.retrievedDocuments.length > 0) {
      insights.push(`Analysis enhanced with context from ${ragContext.retrievedDocuments.length} similar historical documents`);
    }
    
    if (ragContext.averageSimilarity > 0.7) {
      insights.push('High similarity to historical documents suggests reliable pattern recognition');
    }
    
    if (ragContext.enhancementStrategy === 'domain_expertise') {
      insights.push('Industry-specific knowledge applied for improved accuracy');
    }
    
    // Add insights based on retrieved document patterns
    const commonIndustries = ragContext.retrievedDocuments.map(d => d.document.industry);
    const uniqueIndustries = Array.from(new Set(commonIndustries));
    
    if (uniqueIndustries.length === 1 && uniqueIndustries[0] !== 'general') {
      insights.push(`Consistent ${uniqueIndustries[0]} industry patterns detected in historical context`);
    }

    return insights;
  }

  /**
   * Generate contextual recommendations based on RAG analysis
   */
  private async generateContextualRecommendations(
    originalAnalysis: any,
    ragContext: RAGContext  
  ): Promise<string[]> {
    const recommendations: string[] = [];
    
    if (ragContext.averageSimilarity < 0.3) {
      recommendations.push('Consider manual review due to limited historical precedent');
    }
    
    if (ragContext.retrievedDocuments.some(d => d.document.aiConfidence && d.document.aiConfidence > 0.9)) {
      recommendations.push('High-confidence historical patterns suggest reliable analysis');
    }
    
    if (ragContext.enhancementStrategy === 'comparative_analysis') {
      recommendations.push('Compare current results with similar historical documents for validation');
    }
    
    recommendations.push('Leverage historical document insights for improved processing accuracy');
    
    return recommendations;
  }

  /**
   * Calculate confidence boost from RAG context quality
   */
  private calculateConfidenceBoost(ragContext: RAGContext): number {
    if (ragContext.retrievedDocuments.length === 0) return 0;
    
    let boost = 0;
    
    // Base boost from having relevant context
    boost += Math.min(ragContext.retrievedDocuments.length * 2, 10);
    
    // Additional boost from similarity quality
    boost += ragContext.averageSimilarity * 15;
    
    // Strategy-specific boost
    switch (ragContext.enhancementStrategy) {
      case 'comparative_analysis':
        boost += 10;
        break;
      case 'domain_expertise':
        boost += 8;
        break;
      case 'pattern_recognition':
        boost += 6;
        break;
      case 'terminology_support':
        boost += 4;
        break;
    }
    
    return Math.round(Math.min(boost, 25)); // Cap at 25% boost
  }

  /**
   * Generate historical comparisons
   */
  private generateHistoricalComparisons(
    originalAnalysis: any,
    ragContext: RAGContext
  ): string[] {
    const comparisons: string[] = [];
    
    if (ragContext.retrievedDocuments.length > 0) {
      const avgHistoricalConfidence = ragContext.retrievedDocuments
        .filter(d => d.document.aiConfidence)
        .reduce((sum, d) => sum + (d.document.aiConfidence || 0), 0) / ragContext.retrievedDocuments.length;
      
      if (avgHistoricalConfidence > 0) {
        comparisons.push(`Average historical confidence: ${Math.round(avgHistoricalConfidence * 100)}%`);
      }
      
      const industries = Array.from(new Set(ragContext.retrievedDocuments.map(d => d.document.industry)));
      if (industries.length > 1) {
        comparisons.push(`Cross-industry patterns found: ${industries.join(', ')}`);
      }
    }
    
    return comparisons;
  }

  /**
   * Generate industry benchmarks from context
   */
  private async generateIndustryBenchmarks(
    industry: string,
    ragContext: RAGContext
  ): Promise<RAGEnhancedAnalysis['industryBenchmarks']> {
    const industryDocs = ragContext.retrievedDocuments.filter(d => d.document.industry === industry);
    
    if (industryDocs.length === 0) {
      return {
        averageConfidence: 0.7,
        commonPatterns: [],
        typicalProcessingTime: 5000,
        qualityIndicators: ['Limited historical data for benchmarking']
      };
    }
    
    const avgConfidence = industryDocs
      .filter(d => d.document.aiConfidence)
      .reduce((sum, d) => sum + (d.document.aiConfidence || 0), 0) / industryDocs.length;
    
    const commonPatterns = Array.from(new Set(industryDocs
      .map(d => d.document.documentType)
      .filter((type): type is string => Boolean(type))
    ));
    
    return {
      averageConfidence: Math.round((avgConfidence || 0.7) * 100) / 100,
      commonPatterns,
      typicalProcessingTime: 4000, // Estimated based on document complexity
      qualityIndicators: [
        `${industryDocs.length} similar ${industry} documents analyzed`,
        `Average similarity: ${Math.round(ragContext.averageSimilarity * 100)}%`
      ]
    };
  }

  /**
   * Get RAG system status and statistics
   */
  async getRAGStatus(): Promise<{
    isIndexed: boolean;
    totalDocuments: number;
    totalEmbeddings: number;
    averageDocumentLength: number;
    industryBreakdown: Record<string, number>;
  }> {
    const allEmbeddingsForTotal = Array.from(this.documentEmbeddings.values());
    const totalEmbeddings = allEmbeddingsForTotal
      .reduce((sum, embeddings) => sum + embeddings.length, 0);
    
    const industryBreakdown: Record<string, number> = {};
    const allEmbeddingsValues = Array.from(this.documentEmbeddings.values());
    for (const embeddings of allEmbeddingsValues) {
      for (const embedding of embeddings) {
        const industry = embedding.metadata.industry;
        industryBreakdown[industry] = (industryBreakdown[industry] || 0) + 1;
      }
    }
    
    return {
      isIndexed: this.isIndexed,
      totalDocuments: this.documentEmbeddings.size,
      totalEmbeddings,
      averageDocumentLength: totalEmbeddings > 0 ? Math.round(totalEmbeddings / this.documentEmbeddings.size) : 0,
      industryBreakdown
    };
  }

  /**
   * Update document index when new documents are processed
   */
  async updateIndexWithNewDocument(document: Document): Promise<void> {
    if (!this.isIndexed) return;
    
    console.log(`üîÑ Updating RAG index with new document ${document.id}...`);
    
    try {
      await this.createDocumentEmbedding(document);
      console.log(`‚úÖ Updated RAG index with document ${document.id}`);
    } catch (error) {
      console.error(`‚ùå Failed to update index with document ${document.id}:`, error);
    }
  }
}